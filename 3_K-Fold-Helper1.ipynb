{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance(For Numpy Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eu_distance(e1,e2):\n",
    "    return math.sqrt(math.fsum(list(map(lambda x: x**2 ,e1-e2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data and Results for each File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_lines(file) :\n",
    "    with open(file, 'rt') as fd:\n",
    "        convert = [e.split() for e in fd.readlines()]\n",
    "        all_data = []\n",
    "        all_results = []\n",
    "        for line in convert:\n",
    "            data = line\n",
    "            result = data.pop(-1)\n",
    "            all_data.append(data)\n",
    "            all_results.append(result)\n",
    "            \n",
    "        float_data = []\n",
    "        for element in all_data:\n",
    "            float_data.append([float(e) for e in element])\n",
    "        float_data = np.array(float_data)\n",
    "        all_results = np.array(all_results)\n",
    "        \n",
    "        normalized_data = []\n",
    "        for element in float_data:\n",
    "            mean = math.fsum(element)/len(element)\n",
    "            std = math.sqrt(sum((element-mean)**2)/(len(element)-1))\n",
    "            normalized_data.append((element - mean)/std)\n",
    "        normalized_data = np.array(normalized_data)\n",
    "        return normalized_data, all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_distance(s1, s2):\n",
    "    DTW={}\n",
    "\n",
    "    for i in range(len(s1)):\n",
    "        DTW[(i, -1)] = float('inf')\n",
    "    for i in range(len(s2)):\n",
    "        DTW[(-1, i)] = float('inf')\n",
    "    DTW[(-1, -1)] = 0\n",
    "\n",
    "    for i in range(len(s1)):\n",
    "        for j in range(len(s2)):\n",
    "            dist= (s1[i]-s2[j])**2\n",
    "            DTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\n",
    "    return np.sqrt(DTW[len(s1)-1, len(s2)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "__author__ =\"Francois Petitjean\"\n",
    "\n",
    "def performDBA(series, n_iterations=30):\n",
    "    n_series = len(series)\n",
    "    max_length = reduce(max, map(len, series))\n",
    "\n",
    "    cost_mat = np.zeros((max_length, max_length))\n",
    "    delta_mat = np.zeros((max_length, max_length))\n",
    "    path_mat = np.zeros((max_length, max_length), dtype=np.int8)\n",
    "\n",
    "    medoid_ind = approximate_medoid_index(series,cost_mat,delta_mat)\n",
    "    center = series[medoid_ind]\n",
    "\n",
    "    for i in range(0,n_iterations):\n",
    "        center = DBA_update(center, series, cost_mat, path_mat, delta_mat)\n",
    "\n",
    "    return center\n",
    "\n",
    "def approximate_medoid_index(series,cost_mat,delta_mat):\n",
    "    if len(series)<=50:\n",
    "        indices = range(0,len(series))\n",
    "    else:\n",
    "        indices = np.random.choice(range(0,len(series)),50,replace=False)\n",
    "\n",
    "    medoid_ind = -1\n",
    "    best_ss = 1e20\n",
    "    for index_candidate in indices:\n",
    "        candidate = series[index_candidate]\n",
    "        ss = sum_of_squares(candidate,series,cost_mat,delta_mat)\n",
    "        if(medoid_ind==-1 or ss<best_ss):\n",
    "            best_ss = ss\n",
    "            medoid_ind = index_candidate\n",
    "    return medoid_ind\n",
    "\n",
    "def sum_of_squares(s,series,cost_mat,delta_mat):\n",
    "    return sum(map(lambda t:squared_DTW(s,t,cost_mat,delta_mat),series))\n",
    "\n",
    "def DTW(s,t,cost_mat,delta_mat):\n",
    "    return np.sqrt(squared_DTW(s,t,cost_mat,delta_mat))\n",
    "\n",
    "def squared_DTW(s,t,cost_mat,delta_mat):\n",
    "    s_len = len(s)\n",
    "    t_len = len(t)\n",
    "    length = len(s)\n",
    "    fill_delta_mat_dtw(s, t, delta_mat)\n",
    "    cost_mat[0, 0] = delta_mat[0, 0]\n",
    "    for i in range(1, s_len):\n",
    "        cost_mat[i, 0] = cost_mat[i-1, 0]+delta_mat[i, 0]\n",
    "\n",
    "    for j in range(1, t_len):\n",
    "        cost_mat[0, j] = cost_mat[0, j-1]+delta_mat[0, j]\n",
    "\n",
    "    for i in range(1, s_len):\n",
    "        for j in range(1, t_len):\n",
    "            diag,left,top =cost_mat[i-1, j-1], cost_mat[i, j-1], cost_mat[i-1, j]\n",
    "            if(diag <=left):\n",
    "                if(diag<=top):\n",
    "                    res = diag\n",
    "                else:\n",
    "                    res = top\n",
    "            else:\n",
    "                if(left<=top):\n",
    "                    res = left\n",
    "                else:\n",
    "                    res = top\n",
    "            cost_mat[i, j] = res+delta_mat[i, j]\n",
    "    return cost_mat[s_len-1,t_len-1]\n",
    "\n",
    "def fill_delta_mat_dtw(center, s, delta_mat):\n",
    "    slim = delta_mat[:len(center),:len(s)]\n",
    "    np.subtract.outer(center, s,out=slim)\n",
    "    np.square(slim, out=slim)\n",
    "\n",
    "def DBA_update(center, series, cost_mat, path_mat, delta_mat):\n",
    "    options_argmin = [(-1, -1), (0, -1), (-1, 0)]\n",
    "    updated_center = np.zeros(center.shape)\n",
    "    n_elements = np.array(np.zeros(center.shape), dtype=int)\n",
    "    center_length = len(center)\n",
    "    for s in series:\n",
    "        s_len = len(s)\n",
    "        fill_delta_mat_dtw(center, s, delta_mat)\n",
    "        cost_mat[0, 0] = delta_mat[0, 0]\n",
    "        path_mat[0, 0] = -1\n",
    "\n",
    "        for i in range(1, center_length):\n",
    "            cost_mat[i, 0] = cost_mat[i-1, 0]+delta_mat[i, 0]\n",
    "            path_mat[i, 0] = 2\n",
    "\n",
    "        for j in range(1, s_len):\n",
    "            cost_mat[0, j] = cost_mat[0, j-1]+delta_mat[0, j]\n",
    "            path_mat[0, j] = 1\n",
    "\n",
    "        for i in range(1, center_length):\n",
    "            for j in range(1, s_len):\n",
    "                diag,left,top =cost_mat[i-1, j-1], cost_mat[i, j-1], cost_mat[i-1, j]\n",
    "                if(diag <=left):\n",
    "                    if(diag<=top):\n",
    "                        res = diag\n",
    "                        path_mat[i,j] = 0\n",
    "                    else:\n",
    "                        res = top\n",
    "                        path_mat[i,j] = 2\n",
    "                else:\n",
    "                    if(left<=top):\n",
    "                        res = left\n",
    "                        path_mat[i,j] = 1\n",
    "                    else:\n",
    "                        res = top\n",
    "                        path_mat[i,j] = 2\n",
    "\n",
    "                cost_mat[i, j] = res+delta_mat[i, j]\n",
    "\n",
    "        i = center_length-1\n",
    "        j = s_len-1\n",
    "\n",
    "        while(path_mat[i, j] != -1):\n",
    "            updated_center[i] += s[j]\n",
    "            n_elements[i] += 1\n",
    "            move = options_argmin[path_mat[i, j]]\n",
    "            i += move[0]\n",
    "            j += move[1]\n",
    "        assert(i == 0 and j == 0)\n",
    "        updated_center[i] += s[j]\n",
    "        n_elements[i] += 1\n",
    "\n",
    "    return np.divide(updated_center, n_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SubClassSplitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subClassSplitting(mrcp_data,noise_data,mrcp_results,noise_results,threshold):\n",
    "    sum_mrcp_list = list()\n",
    "    for each_mrcp_data in mrcp_data:\n",
    "        sum_mrcp_list.append(math.fsum(each_mrcp_data))\n",
    "    avg_mrcp = float(math.fsum(sum_mrcp_list)/len(mrcp_data))\n",
    "\n",
    "    sum_noise_list = list()\n",
    "    for each_noise_data in noise_data:\n",
    "        sum_noise_list.append(math.fsum(each_noise_data))\n",
    "    avg_noise = float(math.fsum(sum_noise_list)/len(noise_data))\n",
    "\n",
    "#         print('Avg_MRCP: ', avg_mrcp, '\\nAvg_Noise: ', avg_noise)\n",
    "\n",
    "    mrcp_pivot = -1\n",
    "    mrcp_min = float('inf')\n",
    "    for i in range(len(sum_mrcp_list)):\n",
    "        abs_subs = abs(sum_mrcp_list[i] - avg_mrcp)\n",
    "        if  abs_subs < mrcp_min :\n",
    "            mrcp_pivot = i\n",
    "            mrcp_min = abs_subs\n",
    "\n",
    "    noise_pivot = -1\n",
    "    noise_min = float('inf')\n",
    "    for i in range(len(sum_noise_list)):\n",
    "        abs_subs = abs(sum_noise_list[i] - avg_noise)\n",
    "        if  abs_subs < noise_min :\n",
    "            noise_pivot = i\n",
    "            noise_min = abs_subs\n",
    "\n",
    "#         print('MRCP_pivot: ', mrcp_pivot, '\\nNoise_pivot: ', noise_pivot)\n",
    "\n",
    "    #MRCP-------------------------------------------------------------------------------------------------\n",
    "\n",
    "    dist = []\n",
    "    for each_mrcp_data,idx in zip(mrcp_data,range(len(mrcp_data))):\n",
    "        dist.append([eu_distance(each_mrcp_data,mrcp_data[mrcp_pivot]),idx])\n",
    "\n",
    "    sorted_dist = sorted(dist,key=lambda x:x[0])\n",
    "#         print('Sorted_Dist_MRCP: ',sorted_dist[:3])\n",
    "\n",
    "    diff = []\n",
    "    for i in range(1,len(sorted_dist)):\n",
    "        diff.append(sorted_dist[i][0]-sorted_dist[i-1][0]);\n",
    "    diff = np.array(diff)\n",
    "#         print('Diff_MRCP: ',diff[:3])\n",
    "\n",
    "    T_mean = math.fsum(diff)/len(diff)\n",
    "    T_std = math.sqrt(math.fsum((diff-T_mean)**2)/(len(diff)-1)) \n",
    "    T = T_std/2\n",
    "#         print('T_MRCP: ',T)\n",
    "\n",
    "    Class = []\n",
    "    temp_c = []\n",
    "    temp_c.append(sorted_dist[0][1])\n",
    "    for i in range(len(diff)):\n",
    "        if(diff[i] > T):\n",
    "            Class.append(temp_c)\n",
    "            temp_c = []\n",
    "            temp_c.append(sorted_dist[i+1][1])\n",
    "        else:\n",
    "            temp_c.append(sorted_dist[i+1][1])\n",
    "\n",
    "    selected_mrcp_class = list()\n",
    "    removed_mrcp_class = list()\n",
    "    for e in Class:\n",
    "        if len(e)>threshold: selected_mrcp_class.append(e)\n",
    "        else: removed_mrcp_class.append(e)\n",
    "\n",
    "    mrcp_avg = []\n",
    "    for i in range(len(selected_mrcp_class)):\n",
    "        l = []\n",
    "        for e in selected_mrcp_class[i]:\n",
    "            l.append(mrcp_data[e])\n",
    "        mrcp_avg.append(performDBA(l))\n",
    "\n",
    "    l = list()\n",
    "    for i in range(len(removed_mrcp_class)):\n",
    "        for e in removed_mrcp_class[i]:\n",
    "            l.append(e)\n",
    "    l = np.array(l)\n",
    "    filtered_mrcp_data = np.delete(mrcp_data,l,axis=0)\n",
    "\n",
    "    #Noise-------------------------------------------------------------------------------------------------\n",
    "\n",
    "    dist = []\n",
    "    for each_noise_data,idx in zip(noise_data,range(len(noise_data))):\n",
    "        dist.append([eu_distance(each_noise_data,noise_data[noise_pivot]),idx])\n",
    "\n",
    "    sorted_dist = sorted(dist,key=lambda x:x[0])\n",
    "#         print('Sorted_Dist_Noise: ',sorted_dist[:3])\n",
    "\n",
    "    diff = []\n",
    "    for i in range(1,len(sorted_dist)):\n",
    "        diff.append(sorted_dist[i][0]-sorted_dist[i-1][0]);\n",
    "    diff = np.array(diff)\n",
    "#         print('Diff_Noise: ',diff[:3])\n",
    "\n",
    "    T_mean = math.fsum(diff)/len(diff)\n",
    "    T_std = math.sqrt(math.fsum((diff-T_mean)**2)/(len(diff)-1)) \n",
    "    T = T_std/2\n",
    "#         print('T_Noise: ',T)\n",
    "\n",
    "    Class = []\n",
    "    temp_c = []\n",
    "    temp_c.append(sorted_dist[0][1])\n",
    "    for i in range(len(diff)):\n",
    "        if(diff[i] > T):\n",
    "            Class.append(temp_c)\n",
    "            temp_c = []\n",
    "            temp_c.append(sorted_dist[i+1][1])\n",
    "        else:\n",
    "            temp_c.append(sorted_dist[i+1][1])\n",
    "\n",
    "    selected_noise_class = list()\n",
    "    removed_noise_class = list()\n",
    "    for e in Class:\n",
    "        if len(e)>threshold: selected_noise_class.append(e)\n",
    "        else: removed_noise_class.append(e)\n",
    "\n",
    "    noise_avg = []\n",
    "    for i in range(len(selected_noise_class)):\n",
    "        l = []\n",
    "        for e in selected_noise_class[i]:\n",
    "            l.append(noise_data[e])\n",
    "        noise_avg.append(performDBA(l))\n",
    "\n",
    "    l = list()\n",
    "    for i in range(len(removed_noise_class)):\n",
    "        for e in removed_noise_class[i]:\n",
    "            l.append(e)\n",
    "    l = np.array(l)\n",
    "    filtered_noise_data = np.delete(noise_data,l,axis=0)\n",
    "    \n",
    "    return mrcp_avg,noise_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_eu(test_data,test_results,mrcp_avg,noise_avg):\n",
    "    e_results = list()\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for each_test_data in test_data:\n",
    "        e_class = None\n",
    "        min_dist = float('inf')\n",
    "        for avg in mrcp_avg:\n",
    "            dist = eu_distance(each_test_data, avg) \n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                e_class = 'MRCP'\n",
    "        for avg in noise_avg:\n",
    "            dist = eu_distance(each_test_data, avg) \n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                e_class = 'Noise'\n",
    "        e_results.append(e_class)\n",
    "    e_results = np.array(e_results)\n",
    "    for i in range(len(test_data)):\n",
    "        if e_results[i] == 'MRCP' and test_results[i] == 'MRCP' :\n",
    "            TP += 1\n",
    "        elif e_results[i] == 'MRCP' and test_results[i] == 'Noise' :\n",
    "            FP += 1\n",
    "        elif e_results[i] == 'Noise' and test_results[i] == 'MRCP' :\n",
    "            FN += 1\n",
    "        elif e_results[i] == 'Noise' and test_results[i] == 'Noise' :\n",
    "            TN += 1\n",
    "    return TP,FP,FN,TN\n",
    "\n",
    "def score_dtw(test_data,test_results,mrcp_avg,noise_avg):\n",
    "    e_results = list()\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for each_test_data in test_data:\n",
    "        e_class = None\n",
    "        min_dist = float('inf')\n",
    "        for avg in mrcp_avg:\n",
    "            dist = dtw_distance(each_test_data, avg) \n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                e_class = 'MRCP'\n",
    "        for avg in noise_avg:\n",
    "            dist = dtw_distance(each_test_data, avg) \n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                e_class = 'Noise'\n",
    "        e_results.append(e_class)\n",
    "    e_results = np.array(e_results)\n",
    "    for i in range(len(test_data)):\n",
    "        if e_results[i] == 'MRCP' and test_results[i] == 'MRCP' :\n",
    "            TP += 1\n",
    "        elif e_results[i] == 'MRCP' and test_results[i] == 'Noise' :\n",
    "            FP += 1\n",
    "        elif e_results[i] == 'Noise' and test_results[i] == 'MRCP' :\n",
    "            FN += 1\n",
    "        elif e_results[i] == 'Noise' and test_results[i] == 'Noise' :\n",
    "            TN += 1\n",
    "    return TP,FP,FN,TN\n",
    "\n",
    "def cal_f1(TP,FP,FN,TN):\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)*100\n",
    "    f1_score = (2*precision*recall)/(precision+recall)*100\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data and Results for each File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************(( 1-NN DTW with SubClassSplitting ))***************************************\n",
      "Data Participant: 1 got 347 Data\n",
      "( Threshold: 1 )\n",
      "TP: 115\n",
      "FP: 51\n",
      "FN: 69\n",
      "TN: 112\n",
      "F1_Score: 65.71428571428571\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 2 got 351 Data\n",
      "( Threshold: 1 )\n",
      "TP: 165\n",
      "FP: 2\n",
      "FN: 16\n",
      "TN: 168\n",
      "F1_Score: 94.82758620689657\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 3 got 347 Data\n",
      "( Threshold: 1 )\n",
      "TP: 178\n",
      "FP: 26\n",
      "FN: 9\n",
      "TN: 134\n",
      "F1_Score: 91.04859335038363\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 4 got 346 Data\n",
      "( Threshold: 1 )\n",
      "TP: 82\n",
      "FP: 63\n",
      "FN: 96\n",
      "TN: 105\n",
      "F1_Score: 50.77399380804953\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 5 got 331 Data\n",
      "( Threshold: 1 )\n",
      "TP: 162\n",
      "FP: 36\n",
      "FN: 13\n",
      "TN: 120\n",
      "F1_Score: 86.86327077747988\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 6 got 286 Data\n",
      "( Threshold: 1 )\n",
      "TP: 97\n",
      "FP: 33\n",
      "FN: 53\n",
      "TN: 103\n",
      "F1_Score: 69.28571428571428\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 7 got 418 Data\n",
      "( Threshold: 1 )\n",
      "TP: 197\n",
      "FP: 184\n",
      "FN: 17\n",
      "TN: 20\n",
      "F1_Score: 66.21848739495798\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 8 got 415 Data\n",
      "( Threshold: 1 )\n",
      "TP: 56\n",
      "FP: 14\n",
      "FN: 155\n",
      "TN: 190\n",
      "F1_Score: 39.8576512455516\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 9 got 377 Data\n",
      "( Threshold: 1 )\n",
      "TP: 73\n",
      "FP: 56\n",
      "FN: 121\n",
      "TN: 127\n",
      "F1_Score: 45.20123839009288\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Took 34.5814712446928 hours\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('***************************************(( 1-NN DTW with SubClassSplitting ))***************************************')\n",
    "for par in range(1,10):\n",
    "    all_data , all_results = read_all_lines('all data/participant_'+str(par)+'.txt')\n",
    "    print('Data Participant:',par,'got',len(all_data),'Data')\n",
    "    for threshold in range(1,2):\n",
    "        print('( Threshold: {} )'.format(threshold))\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        for i in range(len(all_data)):\n",
    "            test_data = all_data[i]\n",
    "            test_result = all_results[i]\n",
    "            data = np.delete(all_data,i,0)\n",
    "            results = np.delete(all_results,i,0)\n",
    "\n",
    "            mrcp_data = list()\n",
    "            noise_data = list()\n",
    "            mrcp_result = list()\n",
    "            noise_result = list()\n",
    "\n",
    "            for each_data, each_result in zip(data,results):\n",
    "                if each_result == 'MRCP':\n",
    "                    mrcp_data.append(each_data)\n",
    "                    mrcp_result.append(each_result)\n",
    "                else:\n",
    "                    noise_data.append(each_data)\n",
    "                    noise_result.append(each_result)\n",
    "\n",
    "            mrcp_data = np.array(mrcp_data)\n",
    "            noise_data = np.array(noise_data)\n",
    "            mrcp_results = np.array(mrcp_result)\n",
    "            noise_results = np.array(noise_result)\n",
    "\n",
    "            mrcp_avg,noise_avg = subClassSplitting(mrcp_data,noise_data,mrcp_results,noise_results,threshold)\n",
    "\n",
    "            temp_TP,temp_FP,temp_FN,temp_TN = score_dtw([test_data],[test_result],mrcp_avg,noise_avg)\n",
    "            TP += temp_TP\n",
    "            FP += temp_FP\n",
    "            FN += temp_FN\n",
    "            TN += temp_TN\n",
    "    \n",
    "        print('TP:', TP)\n",
    "        print('FP:', FP)\n",
    "        print('FN:', FN)\n",
    "        print('TN:', TN)\n",
    "        f1_score = cal_f1(TP,FP,FN,TN)\n",
    "        print('F1_Score:',f1_score)\n",
    "    print('----------------------------------------------------------------------------------------------------')\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Took {} hours\".format(elapsed_time/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************(( 1-NN DTW with SubClassSplitting ))***************************************\n",
      "Data Participant: 1 got 347 Data\n",
      "( Threshold: 4 )\n",
      "TP: 103\n",
      "FP: 33\n",
      "FN: 81\n",
      "TN: 130\n",
      "F1_Score: 64.375\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 2 got 351 Data\n",
      "( Threshold: 4 )\n",
      "TP: 165\n",
      "FP: 0\n",
      "FN: 16\n",
      "TN: 170\n",
      "F1_Score: 95.37572254335261\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 3 got 347 Data\n",
      "( Threshold: 4 )\n",
      "TP: 176\n",
      "FP: 13\n",
      "FN: 11\n",
      "TN: 147\n",
      "F1_Score: 93.61702127659575\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 4 got 346 Data\n",
      "( Threshold: 4 )\n",
      "TP: 93\n",
      "FP: 45\n",
      "FN: 85\n",
      "TN: 123\n",
      "F1_Score: 58.86075949367089\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 5 got 331 Data\n",
      "( Threshold: 4 )\n",
      "TP: 147\n",
      "FP: 34\n",
      "FN: 28\n",
      "TN: 122\n",
      "F1_Score: 82.58426966292134\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 6 got 286 Data\n",
      "( Threshold: 4 )\n",
      "TP: 93\n",
      "FP: 32\n",
      "FN: 57\n",
      "TN: 104\n",
      "F1_Score: 67.63636363636364\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 7 got 418 Data\n",
      "( Threshold: 4 )\n",
      "TP: 166\n",
      "FP: 109\n",
      "FN: 48\n",
      "TN: 95\n",
      "F1_Score: 67.89366053169734\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 8 got 415 Data\n",
      "( Threshold: 4 )\n",
      "TP: 163\n",
      "FP: 31\n",
      "FN: 48\n",
      "TN: 173\n",
      "F1_Score: 80.49382716049382\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data Participant: 9 got 377 Data\n",
      "( Threshold: 4 )\n",
      "TP: 85\n",
      "FP: 38\n",
      "FN: 109\n",
      "TN: 145\n",
      "F1_Score: 53.62776025236592\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Took 26.476651260786586 hours\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('***************************************(( 1-NN DTW with SubClassSplitting ))***************************************')\n",
    "for par in range(1,10):\n",
    "    all_data , all_results = read_all_lines('all data/participant_'+str(par)+'.txt')\n",
    "    print('Data Participant:',par,'got',len(all_data),'Data')\n",
    "    for threshold in range(4,5):\n",
    "        print('( Threshold: {} )'.format(threshold))\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        for i in range(len(all_data)):\n",
    "            test_data = all_data[i]\n",
    "            test_result = all_results[i]\n",
    "            data = np.delete(all_data,i,0)\n",
    "            results = np.delete(all_results,i,0)\n",
    "\n",
    "            mrcp_data = list()\n",
    "            noise_data = list()\n",
    "            mrcp_result = list()\n",
    "            noise_result = list()\n",
    "\n",
    "            for each_data, each_result in zip(data,results):\n",
    "                if each_result == 'MRCP':\n",
    "                    mrcp_data.append(each_data)\n",
    "                    mrcp_result.append(each_result)\n",
    "                else:\n",
    "                    noise_data.append(each_data)\n",
    "                    noise_result.append(each_result)\n",
    "\n",
    "            mrcp_data = np.array(mrcp_data)\n",
    "            noise_data = np.array(noise_data)\n",
    "            mrcp_results = np.array(mrcp_result)\n",
    "            noise_results = np.array(noise_result)\n",
    "\n",
    "            mrcp_avg,noise_avg = subClassSplitting(mrcp_data,noise_data,mrcp_results,noise_results,threshold)\n",
    "\n",
    "            temp_TP,temp_FP,temp_FN,temp_TN = score_dtw([test_data],[test_result],mrcp_avg,noise_avg)\n",
    "            TP += temp_TP\n",
    "            FP += temp_FP\n",
    "            FN += temp_FN\n",
    "            TN += temp_TN\n",
    "    \n",
    "        print('TP:', TP)\n",
    "        print('FP:', FP)\n",
    "        print('FN:', FN)\n",
    "        print('TN:', TN)\n",
    "        f1_score = cal_f1(TP,FP,FN,TN)\n",
    "        print('F1_Score:',f1_score)\n",
    "    print('----------------------------------------------------------------------------------------------------')\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Took {} hours\".format(elapsed_time/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
