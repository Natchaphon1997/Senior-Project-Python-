{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from pylab import plot, show, savefig, xlim, figure, hold, ylim, legend, boxplot, setp, axes\n",
    "from ipynb.fs.full.BoxPlot import box_plot, box_plot_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance(For Numpy Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_euclidean(e1,e2):\n",
    "    return math.sqrt(math.fsum(list(map(lambda x: x**2 ,e1-e2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data and Results for each File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_lines(file) :\n",
    "    with open(file, 'rt') as fd:\n",
    "        convert = [e.split() for e in fd.readlines()]\n",
    "        all_data = []\n",
    "        all_results = []\n",
    "        for line in convert:\n",
    "            data = line\n",
    "            result = data.pop(-1)\n",
    "            all_data.append(data)\n",
    "            all_results.append(result)\n",
    "            \n",
    "        float_data = []\n",
    "        for element in all_data:\n",
    "            float_data.append([float(e) for e in element])\n",
    "        float_data = np.array(float_data)\n",
    "        all_results = np.array(all_results)\n",
    "        \n",
    "        normalized_data = []\n",
    "        for element in float_data:\n",
    "            mean = math.fsum(element)/len(element)\n",
    "            std = math.sqrt(sum((element-mean)**2)/(len(element)-1))\n",
    "            normalized_data.append((element - mean)/std)\n",
    "        normalized_data = np.array(normalized_data)\n",
    "        return normalized_data, all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_distance(s1, s2):\n",
    "    DTW={}\n",
    "\n",
    "    for i in range(len(s1)):\n",
    "        DTW[(i, -1)] = float('inf')\n",
    "    for i in range(len(s2)):\n",
    "        DTW[(-1, i)] = float('inf')\n",
    "    DTW[(-1, -1)] = 0\n",
    "\n",
    "    for i in range(len(s1)):\n",
    "        for j in range(len(s2)):\n",
    "            dist= (s1[i]-s2[j])**2\n",
    "            DTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\n",
    "    return np.sqrt(DTW[len(s1)-1, len(s2)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "__author__ =\"Francois Petitjean\"\n",
    "\n",
    "def performDBA(series, n_iterations=10):\n",
    "    n_series = len(series)\n",
    "    max_length = reduce(max, map(len, series))\n",
    "\n",
    "    cost_mat = np.zeros((max_length, max_length))\n",
    "    delta_mat = np.zeros((max_length, max_length))\n",
    "    path_mat = np.zeros((max_length, max_length), dtype=np.int8)\n",
    "\n",
    "    medoid_ind = approximate_medoid_index(series,cost_mat,delta_mat)\n",
    "    center = series[medoid_ind]\n",
    "\n",
    "    for i in range(0,n_iterations):\n",
    "        center = DBA_update(center, series, cost_mat, path_mat, delta_mat)\n",
    "\n",
    "    return center\n",
    "\n",
    "def approximate_medoid_index(series,cost_mat,delta_mat):\n",
    "    if len(series)<=50:\n",
    "        indices = range(0,len(series))\n",
    "    else:\n",
    "        indices = np.random.choice(range(0,len(series)),50,replace=False)\n",
    "\n",
    "    medoid_ind = -1\n",
    "    best_ss = 1e20\n",
    "    for index_candidate in indices:\n",
    "        candidate = series[index_candidate]\n",
    "        ss = sum_of_squares(candidate,series,cost_mat,delta_mat)\n",
    "        if(medoid_ind==-1 or ss<best_ss):\n",
    "            best_ss = ss\n",
    "            medoid_ind = index_candidate\n",
    "    return medoid_ind\n",
    "\n",
    "def sum_of_squares(s,series,cost_mat,delta_mat):\n",
    "    return sum(map(lambda t:squared_DTW(s,t,cost_mat,delta_mat),series))\n",
    "\n",
    "def DTW(s,t,cost_mat,delta_mat):\n",
    "    return np.sqrt(squared_DTW(s,t,cost_mat,delta_mat))\n",
    "\n",
    "def squared_DTW(s,t,cost_mat,delta_mat):\n",
    "    s_len = len(s)\n",
    "    t_len = len(t)\n",
    "    length = len(s)\n",
    "    fill_delta_mat_dtw(s, t, delta_mat)\n",
    "    cost_mat[0, 0] = delta_mat[0, 0]\n",
    "    for i in range(1, s_len):\n",
    "        cost_mat[i, 0] = cost_mat[i-1, 0]+delta_mat[i, 0]\n",
    "\n",
    "    for j in range(1, t_len):\n",
    "        cost_mat[0, j] = cost_mat[0, j-1]+delta_mat[0, j]\n",
    "\n",
    "    for i in range(1, s_len):\n",
    "        for j in range(1, t_len):\n",
    "            diag,left,top =cost_mat[i-1, j-1], cost_mat[i, j-1], cost_mat[i-1, j]\n",
    "            if(diag <=left):\n",
    "                if(diag<=top):\n",
    "                    res = diag\n",
    "                else:\n",
    "                    res = top\n",
    "            else:\n",
    "                if(left<=top):\n",
    "                    res = left\n",
    "                else:\n",
    "                    res = top\n",
    "            cost_mat[i, j] = res+delta_mat[i, j]\n",
    "    return cost_mat[s_len-1,t_len-1]\n",
    "\n",
    "def fill_delta_mat_dtw(center, s, delta_mat):\n",
    "    slim = delta_mat[:len(center),:len(s)]\n",
    "    np.subtract.outer(center, s,out=slim)\n",
    "    np.square(slim, out=slim)\n",
    "\n",
    "def DBA_update(center, series, cost_mat, path_mat, delta_mat):\n",
    "    options_argmin = [(-1, -1), (0, -1), (-1, 0)]\n",
    "    updated_center = np.zeros(center.shape)\n",
    "    n_elements = np.array(np.zeros(center.shape), dtype=int)\n",
    "    center_length = len(center)\n",
    "    for s in series:\n",
    "        s_len = len(s)\n",
    "        fill_delta_mat_dtw(center, s, delta_mat)\n",
    "        cost_mat[0, 0] = delta_mat[0, 0]\n",
    "        path_mat[0, 0] = -1\n",
    "\n",
    "        for i in range(1, center_length):\n",
    "            cost_mat[i, 0] = cost_mat[i-1, 0]+delta_mat[i, 0]\n",
    "            path_mat[i, 0] = 2\n",
    "\n",
    "        for j in range(1, s_len):\n",
    "            cost_mat[0, j] = cost_mat[0, j-1]+delta_mat[0, j]\n",
    "            path_mat[0, j] = 1\n",
    "\n",
    "        for i in range(1, center_length):\n",
    "            for j in range(1, s_len):\n",
    "                diag,left,top =cost_mat[i-1, j-1], cost_mat[i, j-1], cost_mat[i-1, j]\n",
    "                if(diag <=left):\n",
    "                    if(diag<=top):\n",
    "                        res = diag\n",
    "                        path_mat[i,j] = 0\n",
    "                    else:\n",
    "                        res = top\n",
    "                        path_mat[i,j] = 2\n",
    "                else:\n",
    "                    if(left<=top):\n",
    "                        res = left\n",
    "                        path_mat[i,j] = 1\n",
    "                    else:\n",
    "                        res = top\n",
    "                        path_mat[i,j] = 2\n",
    "\n",
    "                cost_mat[i, j] = res+delta_mat[i, j]\n",
    "\n",
    "        i = center_length-1\n",
    "        j = s_len-1\n",
    "\n",
    "        while(path_mat[i, j] != -1):\n",
    "            updated_center[i] += s[j]\n",
    "            n_elements[i] += 1\n",
    "            move = options_argmin[path_mat[i, j]]\n",
    "            i += move[0]\n",
    "            j += move[1]\n",
    "        assert(i == 0 and j == 0)\n",
    "        updated_center[i] += s[j]\n",
    "        n_elements[i] += 1\n",
    "\n",
    "    return np.divide(updated_center, n_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_eu(test_data,test_results,mrcp_avg,noise_avg):\n",
    "    e_results = list()\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for each_test_data in test_data:\n",
    "        e_class = None\n",
    "        min_dist = float('inf')\n",
    "        for avg in mrcp_avg:\n",
    "            dist = np_euclidean(each_test_data, avg) \n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                e_class = 'MRCP'\n",
    "        for avg in noise_avg:\n",
    "            dist = np_euclidean(each_test_data, avg) \n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                e_class = 'Noise'\n",
    "        e_results.append(e_class)\n",
    "    e_results = np.array(e_results)\n",
    "    for i in range(len(test_data)):\n",
    "        if e_results[i] == 'MRCP' and test_results[i] == 'MRCP' :\n",
    "            TP += 1\n",
    "        elif e_results[i] == 'MRCP' and test_results[i] == 'Noise' :\n",
    "            FP += 1\n",
    "        elif e_results[i] == 'Noise' and test_results[i] == 'MRCP' :\n",
    "            FN += 1\n",
    "        elif e_results[i] == 'Noise' and test_results[i] == 'Noise' :\n",
    "            TN += 1\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)*100\n",
    "    f1_score = (2*precision*recall)/(precision+recall)*100\n",
    "    return accuracy,f1_score\n",
    "\n",
    "def score_dtw(test_data,test_results,mrcp_avg,noise_avg):\n",
    "    e_results = list()\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for each_test_data in test_data:\n",
    "        e_class = None\n",
    "        min_dist = float('inf')\n",
    "        for avg in mrcp_avg:\n",
    "            dist = dtw_distance(each_test_data, avg) \n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                e_class = 'MRCP'\n",
    "        for avg in noise_avg:\n",
    "            dist = dtw_distance(each_test_data, avg) \n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                e_class = 'Noise'\n",
    "        e_results.append(e_class)\n",
    "    e_results = np.array(e_results)\n",
    "    for i in range(len(test_data)):\n",
    "        if e_results[i] == 'MRCP' and test_results[i] == 'MRCP' :\n",
    "            TP += 1\n",
    "        elif e_results[i] == 'MRCP' and test_results[i] == 'Noise' :\n",
    "            FP += 1\n",
    "        elif e_results[i] == 'Noise' and test_results[i] == 'MRCP' :\n",
    "            FN += 1\n",
    "        elif e_results[i] == 'Noise' and test_results[i] == 'Noise' :\n",
    "            TN += 1\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)*100\n",
    "    f1_score = (2*precision*recall)/(precision+recall)*100\n",
    "    return accuracy,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data and Results for each File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************************\n",
      "Data Participant: 1 \n",
      "\n",
      "F1_score_ue:  77.02702702702703\n",
      "F1_score_dtw:  77.02702702702703\n",
      "********************************************************************************************\n",
      "********************************************************************************************\n",
      "Data Participant: 2 \n",
      "\n",
      "F1_score_ue:  90.09009009009009\n",
      "F1_score_dtw:  90.09009009009009\n",
      "********************************************************************************************\n",
      "********************************************************************************************\n",
      "Data Participant: 3 \n",
      "\n",
      "F1_score_ue:  87.93103448275862\n",
      "F1_score_dtw:  93.22033898305084\n",
      "********************************************************************************************\n",
      "********************************************************************************************\n",
      "Data Participant: 4 \n",
      "\n",
      "F1_score_ue:  65.73426573426573\n",
      "F1_score_dtw:  63.23529411764706\n",
      "********************************************************************************************\n",
      "********************************************************************************************\n",
      "Data Participant: 5 \n",
      "\n",
      "F1_score_ue:  81.9047619047619\n",
      "F1_score_dtw:  82.6923076923077\n",
      "********************************************************************************************\n",
      "********************************************************************************************\n",
      "Data Participant: 6 \n",
      "\n",
      "F1_score_ue:  70.0\n",
      "F1_score_dtw:  69.56521739130434\n",
      "********************************************************************************************\n",
      "********************************************************************************************\n",
      "Data Participant: 7 \n",
      "\n",
      "F1_score_ue:  59.85401459854014\n",
      "F1_score_dtw:  68.14814814814814\n",
      "********************************************************************************************\n",
      "********************************************************************************************\n",
      "Data Participant: 8 \n",
      "\n",
      "F1_score_ue:  76.62337662337661\n",
      "F1_score_dtw:  73.41772151898734\n",
      "********************************************************************************************\n",
      "********************************************************************************************\n",
      "Data Participant: 9 \n",
      "\n",
      "F1_score_ue:  71.87500000000001\n",
      "F1_score_dtw:  74.80916030534351\n",
      "********************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "threshold = 5  \n",
    "for par in range(1,10):\n",
    "    data , results = read_all_lines('training data/participant_'+str(par)+'.txt')\n",
    "    test_data , test_results = read_all_lines('test data/participant_'+str(par)+'.txt')\n",
    "\n",
    "    mrcp_data = list()\n",
    "    noise_data = list()\n",
    "    mrcp_result = list()\n",
    "    noise_result = list()\n",
    "\n",
    "    for each_data, each_result in zip(data,results):\n",
    "        if each_result == 'MRCP':\n",
    "            mrcp_data.append(each_data)\n",
    "            mrcp_result.append(each_result)\n",
    "        else:\n",
    "            noise_data.append(each_data)\n",
    "            noise_result.append(each_result)\n",
    "\n",
    "    mrcp_data = np.array(mrcp_data)\n",
    "    noise_data = np.array(noise_data)\n",
    "    mrcp_results = np.array(mrcp_result)\n",
    "    noise_results = np.array(noise_result)\n",
    "\n",
    "    sum_mrcp_list = list()\n",
    "    for each_mrcp_data in mrcp_data:\n",
    "        sum_mrcp_list.append(math.fsum(each_mrcp_data))\n",
    "    avg_mrcp = float(math.fsum(sum_mrcp_list)/len(mrcp_data))\n",
    "\n",
    "    sum_noise_list = list()\n",
    "    for each_noise_data in noise_data:\n",
    "        sum_noise_list.append(math.fsum(each_noise_data))\n",
    "    avg_noise = float(math.fsum(sum_noise_list)/len(noise_data))\n",
    "\n",
    "#         print('Avg_MRCP: ', avg_mrcp, '\\nAvg_Noise: ', avg_noise)\n",
    "\n",
    "    mrcp_pivot = -1\n",
    "    mrcp_min = float('inf')\n",
    "    for i in range(len(sum_mrcp_list)):\n",
    "        abs_subs = abs(sum_mrcp_list[i] - avg_mrcp)\n",
    "        if  abs_subs < mrcp_min :\n",
    "            mrcp_pivot = i\n",
    "            mrcp_min = abs_subs\n",
    "\n",
    "    noise_pivot = -1\n",
    "    noise_min = float('inf')\n",
    "    for i in range(len(sum_noise_list)):\n",
    "        abs_subs = abs(sum_noise_list[i] - avg_noise)\n",
    "        if  abs_subs < noise_min :\n",
    "            noise_pivot = i\n",
    "            noise_min = abs_subs\n",
    "\n",
    "#         print('MRCP_pivot: ', mrcp_pivot, '\\nNoise_pivot: ', noise_pivot)\n",
    "\n",
    "    #MRCP-------------------------------------------------------------------------------------------------\n",
    "\n",
    "    dist = []\n",
    "    for each_mrcp_data,idx in zip(mrcp_data,range(len(mrcp_data))):\n",
    "        dist.append([np_euclidean(each_mrcp_data,mrcp_data[mrcp_pivot]),idx])\n",
    "\n",
    "    sorted_dist = sorted(dist,key=lambda x:x[0])\n",
    "#         print('Sorted_Dist_MRCP: ',sorted_dist[:3])\n",
    "\n",
    "    diff = []\n",
    "    for i in range(1,len(sorted_dist)):\n",
    "        diff.append(sorted_dist[i][0]-sorted_dist[i-1][0]);\n",
    "    diff = np.array(diff)\n",
    "#         print('Diff_MRCP: ',diff[:3])\n",
    "\n",
    "    T_mean = math.fsum(diff)/len(diff)\n",
    "    T_std = math.sqrt(math.fsum((diff-T_mean)**2)/(len(diff)-1)) \n",
    "    T = T_std/2\n",
    "#         print('T_MRCP: ',T)\n",
    "\n",
    "    Class = []\n",
    "    temp_c = []\n",
    "    temp_c.append(sorted_dist[0][1])\n",
    "    for i in range(len(diff)):\n",
    "        if(diff[i] > T):\n",
    "            Class.append(temp_c)\n",
    "            temp_c = []\n",
    "            temp_c.append(sorted_dist[i+1][1])\n",
    "        else:\n",
    "            temp_c.append(sorted_dist[i+1][1])\n",
    "\n",
    "#     plt.figure(figsize=(30,len(Class)))\n",
    "#     count = 1\n",
    "#     for each_class in Class:\n",
    "#         index = []\n",
    "#         plt.subplot(len(Class)/4+1,4,count)\n",
    "#         for idx in each_class:\n",
    "#             x = range(len(mrcp_data[idx]))\n",
    "#             plt.plot(x,mrcp_data[idx])\n",
    "#             index.append(idx)\n",
    "#         #plt.xlabel('MRCP : '+str(index))\n",
    "#         count += 1\n",
    "#     plt.show()\n",
    "\n",
    "    selected_mrcp_class = list()\n",
    "    removed_mrcp_class = list()\n",
    "    for e in Class:\n",
    "        if len(e)>threshold: selected_mrcp_class.append(e)\n",
    "        else: removed_mrcp_class.append(e)\n",
    "\n",
    "    mrcp_avg = []\n",
    "    for i in range(len(selected_mrcp_class)):\n",
    "        l = []\n",
    "        for e in selected_mrcp_class[i]:\n",
    "            l.append(mrcp_data[e])\n",
    "        mrcp_avg.append(performDBA(l))\n",
    "\n",
    "    l = list()\n",
    "    for i in range(len(removed_mrcp_class)):\n",
    "        for e in removed_mrcp_class[i]:\n",
    "            l.append(e)\n",
    "    l = np.array(l)\n",
    "    filtered_mrcp_data = np.delete(mrcp_data,l,axis=0)\n",
    "\n",
    "#     plt.figure(figsize=(30,len(mrcp_avg)))\n",
    "#     count = 1\n",
    "#     for each_class in mrcp_avg:\n",
    "#         plt.subplot(len(mrcp_avg)/4+1,4,count)\n",
    "#         x = range(len(each_class))\n",
    "#         plt.plot(x,each_class)\n",
    "#         count += 1\n",
    "#     plt.show()\n",
    "\n",
    "    #Noise-------------------------------------------------------------------------------------------------\n",
    "\n",
    "    dist = []\n",
    "    for each_noise_data,idx in zip(noise_data,range(len(noise_data))):\n",
    "        dist.append([np_euclidean(each_noise_data,noise_data[noise_pivot]),idx])\n",
    "\n",
    "    sorted_dist = sorted(dist,key=lambda x:x[0])\n",
    "#         print('Sorted_Dist_Noise: ',sorted_dist[:3])\n",
    "\n",
    "    diff = []\n",
    "    for i in range(1,len(sorted_dist)):\n",
    "        diff.append(sorted_dist[i][0]-sorted_dist[i-1][0]);\n",
    "    diff = np.array(diff)\n",
    "#         print('Diff_Noise: ',diff[:3])\n",
    "\n",
    "    T_mean = math.fsum(diff)/len(diff)\n",
    "    T_std = math.sqrt(math.fsum((diff-T_mean)**2)/(len(diff)-1)) \n",
    "    T = T_std/2\n",
    "#         print('T_Noise: ',T)\n",
    "\n",
    "    Class = []\n",
    "    temp_c = []\n",
    "    temp_c.append(sorted_dist[0][1])\n",
    "    for i in range(len(diff)):\n",
    "        if(diff[i] > T):\n",
    "            Class.append(temp_c)\n",
    "            temp_c = []\n",
    "            temp_c.append(sorted_dist[i+1][1])\n",
    "        else:\n",
    "            temp_c.append(sorted_dist[i+1][1])\n",
    "\n",
    "#     plt.figure(figsize=(30,len(Class)))\n",
    "#     count = 1\n",
    "#     for each_class in Class:\n",
    "#         index = []\n",
    "#         plt.subplot(len(Class)/4+1,4,count)\n",
    "#         for idx in each_class:\n",
    "#             x = range(len(noise_data[idx]))\n",
    "#             plt.plot(x,noise_data[idx])\n",
    "#             index.append(idx)\n",
    "#         #plt.xlabel('Noise : '+str(index))\n",
    "#         count += 1\n",
    "#     plt.show()\n",
    "\n",
    "    selected_noise_class = list()\n",
    "    removed_noise_class = list()\n",
    "    for e in Class:\n",
    "        if len(e)>threshold: selected_noise_class.append(e)\n",
    "        else: removed_noise_class.append(e)\n",
    "\n",
    "    noise_avg = []\n",
    "    for i in range(len(selected_noise_class)):\n",
    "        l = []\n",
    "        for e in selected_noise_class[i]:\n",
    "            l.append(noise_data[e])\n",
    "        noise_avg.append(performDBA(l))\n",
    "\n",
    "    l = list()\n",
    "    for i in range(len(removed_noise_class)):\n",
    "        for e in removed_noise_class[i]:\n",
    "            l.append(e)\n",
    "    l = np.array(l)\n",
    "    filtered_noise_data = np.delete(noise_data,l,axis=0)\n",
    "\n",
    "#     plt.figure(figsize=(30,len(noise_avg)))\n",
    "#     count = 1\n",
    "#     for each_class in noise_avg:\n",
    "#         plt.subplot(len(noise_avg)/4+1,4,count)\n",
    "#         x = range(len(each_class))\n",
    "#         plt.plot(x,each_class)\n",
    "#         count += 1\n",
    "#     plt.show()\n",
    "    print('********************************************************************************************')\n",
    "    print('Data Participant:',par,'\\n')\n",
    "    acc_eu , f1_score_eu = score_eu(test_data,test_results,filtered_mrcp_data,filtered_noise_data)\n",
    "    print('F1_score_ue: ',f1_score_eu)\n",
    "    acc_dtw , f1_score_dtw = score_dtw(test_data,test_results,filtered_mrcp_data,filtered_noise_data)\n",
    "    print('F1_score_dtw: ',f1_score_dtw)\n",
    "    print('********************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
